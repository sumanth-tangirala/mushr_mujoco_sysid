import torch


class MushrPlant:
    def __init__(self):
        self.velocity_idx = 0
        self.steering_idx = 1
        self.R_PI_2 = torch.Tensor([[0.0, -1.0], [1.0, 0.0]])
        self.PolyDeg = 3
        self.L = 0.31
        self.mass = 3.5

    def beta(self, delta):
        return torch.atan(0.5 * torch.tan(delta))

    def poly_eval(self, poly, x):
        val = 0
        for i in range(self.PolyDeg + 1):
            deg = torch.Tensor([int(self.PolyDeg - i)])
            xp = poly[i] * torch.pow(x, deg)
            val += xp
            # print(f"i: {i} deg: {deg} poly: {poly[i]} val: {val}")
            # print(f"xp: {xp} val: {val} ")
        # xaux * x
        return val

    def SE2(self, x, y, th):
        c = torch.cos(th)
        s = torch.sin(th)
        M = [[c, -s, x], [s, c, y], [0, 0, 1]]
        # print(f"M {M}")
        return torch.Tensor(M)

    def AdjointMap(self, pose):
        # adjM.block<2, 2>(0, 0) = pose.rotation<Eigen::Matrix2d>();
        # adjM(0, 2) = pose.y();
        # adjM(1, 2) = -pose.x();

        M = torch.eye(3)
        M[:2, :2] = pose[:2, :2]
        M[0, 2] = pose[1, 2]
        M[1, 2] = -pose[0, 2]
        # print(f"pose {pose}")
        # print(f"M {M}")
        return torch.Tensor(M)

    def adjoint(self, pose, xd):
        ad = self.AdjointMap(pose)
        return ad @ xd

    def rotation_mat(self, theta):
        c = torch.cos(theta)
        s = torch.sin(theta)
        M = [[c, -s], [s, c]]

        return torch.Tensor(M)

    def SE2_expmap(self, xd):
        v = xd[0:2]
        w = xd[2]
        if torch.abs(w) < 1e-10:
            # print("SE2_expmap zero");
            # print(f"xd {xd}")
            return self.SE2(xd[0], xd[1], xd[2])
        else:
            # const Rot2 R(Rot2::fromAngle(w));
            R = self.rotation_mat(w)
            v_ortho = self.R_PI_2 @ v
            # // points towards rot center
            t = (v_ortho - R @ v_ortho) / w
            # print("SE2_expmap NON zero");
            return self.SE2(t[0], t[1], w)

    def integrate_SE2(self, x, xdot, dt):
        xdot_dt = xdot * dt
        exmap_xdot_dt = self.SE2_expmap(xdot_dt)
        xj = x @ exmap_xdot_dt
        return xj

    def integrate_euler(self, x, xdot, dt):
        return x + xdot * dt

    def xdot(self, xd0, ut, dt):
        delta = ut[self.steering_idx]
        # const double delta{ mushr_types::Control::evaluate_polynomial(steering_poly, deltaIn, delta_H_deltaIn) };

        # Uaccel = ut[self.velocity_idx] ;
        # AccIn = Uaccel * paramVel ;
        AccIn = ut[self.velocity_idx]

        # const double Vprev_pos{ xd0.head(2).norm() };
        Vprev_pos = torch.norm(xd0[:2])
        Vprev = torch.copysign(Vprev_pos, AccIn)

        beta = self.beta(delta)
        beta_prev = torch.atan2(xd0[1], xd0[0])
        norm2 = Vprev_pos * Vprev_pos
        # SquaredNorm

        omega = 2.0 * torch.sin(beta) / self.L
        omega_prev = 2.0 * torch.sin(beta_prev) / self.L

        # print(f"omega: {omega} omega_prev: {omega_prev}")
        # print(f"beta: {beta} beta_prev: {beta_prev}")
        # print("TBeta")
        T_beta = self.SE2(0.0, 0.0, beta)
        T_beta_prev = self.SE2(0.0, 0.0, beta_prev)

        Tbpinv = T_beta_prev.inverse()
        # qd0_sign = torch.copysign(1.0, AccIn) ;
        # print(f"xd0 {xd0}")
        # print(f"Tbpinv {Tbpinv}")
        qd0_adj = self.adjoint(Tbpinv, xd0)
        one = torch.Tensor([1.0])
        qd0_sign = torch.copysign(one, AccIn)  # qd0_sign * qd0_adj ;
        # qd0 = torch.copysign(qd0_adj, AccIn) # qd0_sign * qd0_adj ;
        qd0 = qd0_sign * qd0_adj
        qdd = torch.Tensor([AccIn, 0.0, 0.0])
        xd1_zero = self.integrate_euler(qd0, qdd, dt)

        # print(f"qdd {qdd}")
        # print(f"qd0_adj {qd0_adj}")

        Vcurr_pos = torch.norm(xd1_zero[0:2])
        Vcurr = torch.copysign(Vcurr_pos, AccIn)

        thd_prev = omega_prev * Vprev
        thd_curr = omega * Vcurr
        friction = 1.0
        # fixing for now...
        w_new = torch.Tensor([0, 0, (thd_curr - thd_prev) * friction])
        xd1Adj = self.adjoint(T_beta, xd1_zero)
        xd1 = xd1Adj + w_new

        # print(f"T_beta {T_beta}")
        # print(f"xd1_zero {xd1_zero}")
        # print(f"xd1Adj {xd1Adj}")
        # print(f"w_new {w_new}")

        return xd1


def to_file(ofs, x, y):
    s = ""
    # // Eqs. 116,117 on micro lie theory
    r21 = x[2, 0]
    r11 = x[0, 0]
    th = torch.atan2(r21, r11)

    s += str(float(x[0, 2])) + " "
    s += str(float(x[1, 2])) + " "
    s += str(float(th)) + " "

    for e in y:
        s += str(float(e)) + " "
    s += "\n"
    # print(f"x: {x}")
    # print(f"line: {s}")
    ofs.write(s)


def test():
    GT_traj = [
        [0.0, 1.0, 0.00000, 1.57080, 0.00000, 0.00000, 0.00000],
        [0.10000, 1.00005, -0.00035, 1.57046, -0.00353, -0.00051, -0.00332],
        [0.20000, 1.00015, -0.00106, 1.56980, -0.00705, -0.00102, -0.00663],
        [0.30000, 1.00030, -0.00212, 1.56881, -0.01058, -0.00152, -0.00995],
        [0.40000, 1.00050, -0.00353, 1.56748, -0.01410, -0.00203, -0.01326],
        [0.50000, 1.00075, -0.00529, 1.56582, -0.01763, -0.00254, -0.01658],
        [0.60000, 1.00104, -0.00741, 1.56383, -0.02115, -0.00305, -0.01990],
        [0.70000, 1.00138, -0.00988, 1.56151, -0.02468, -0.00356, -0.02321],
        [0.80000, 1.00175, -0.01270, 1.55886, -0.02820, -0.00406, -0.02653],
        [0.90000, 1.00217, -0.01588, 1.55587, -0.03173, -0.00457, -0.02984],
        [1.00000, 1.00262, -0.01942, 1.55256, -0.03526, -0.00508, -0.03316],
        [1.10000, 1.00310, -0.02330, 1.54891, -0.03878, -0.00559, -0.03648],
        [1.20000, 1.00361, -0.02755, 1.54493, -0.04231, -0.00609, -0.03979],
        [1.30000, 1.00414, -0.03215, 1.54062, -0.04583, -0.00660, -0.04311],
        [1.40000, 1.00469, -0.03710, 1.53598, -0.04936, -0.00711, -0.04642],
        [1.50000, 1.00525, -0.04242, 1.53100, -0.05288, -0.00762, -0.04974],
        [1.60000, 1.00582, -0.04809, 1.52570, -0.05641, -0.00813, -0.05306],
        [1.70000, 1.00640, -0.05412, 1.52006, -0.05994, -0.00863, -0.05637],
        [1.80000, 1.00697, -0.06050, 1.51409, -0.06346, -0.00914, -0.05969],
        [1.90000, 1.00753, -0.06725, 1.50779, -0.06699, -0.00965, -0.06300],
        [2.00000, 1.00808, -0.07435, 1.50116, -0.07051, -0.01016, -0.06632],
        [2.10000, 1.00860, -0.08181, 1.49420, -0.07404, -0.01067, -0.06964],
        [2.20000, 1.00910, -0.08963, 1.48690, -0.07756, -0.01117, -0.07295],
        [2.30000, 1.00955, -0.09781, 1.47927, -0.08109, -0.01168, -0.07627],
        [2.40000, 1.00995, -0.10635, 1.47132, -0.08461, -0.01219, -0.07958],
        [2.50000, 1.01031, -0.11525, 1.46303, -0.08814, -0.01270, -0.08290],
        [2.60000, 1.01059, -0.12451, 1.45440, -0.09167, -0.01321, -0.08622],
        [2.70000, 1.01081, -0.13412, 1.44545, -0.09519, -0.01371, -0.08953],
        [2.80000, 1.01094, -0.14409, 1.43617, -0.09872, -0.01422, -0.09285],
        [2.90000, 1.01097, -0.15442, 1.42655, -0.10224, -0.01473, -0.09616],
        [3.00000, 1.01091, -0.16511, 1.41660, -0.10577, -0.01524, -0.09948],
        [3.10000, 1.01073, -0.17615, 1.40632, -0.10929, -0.01574, -0.10280],
        [3.20000, 1.01043, -0.18754, 1.39571, -0.11282, -0.01625, -0.10611],
        [3.30000, 1.00998, -0.19929, 1.38477, -0.11634, -0.01676, -0.10943],
        [3.40000, 1.00940, -0.21139, 1.37349, -0.11987, -0.01727, -0.11274],
        [3.50000, 1.00865, -0.22383, 1.36189, -0.12340, -0.01778, -0.11606],
        [3.60000, 1.00773, -0.23662, 1.34995, -0.12692, -0.01828, -0.11938],
        [3.70000, 1.00662, -0.24975, 1.33768, -0.13045, -0.01879, -0.12269],
        [3.80000, 1.00532, -0.26323, 1.32508, -0.13397, -0.01930, -0.12601],
        [3.90000, 1.00381, -0.27704, 1.31215, -0.13750, -0.01981, -0.12932],
        [4.00000, 1.00207, -0.29118, 1.29888, -0.14102, -0.02032, -0.13264],
        [4.10000, 1.00010, -0.30565, 1.28529, -0.14455, -0.02082, -0.13596],
        [4.20000, 0.99787, -0.32044, 1.27136, -0.14807, -0.02133, -0.13927],
        [4.30000, 0.99538, -0.33555, 1.25710, -0.15160, -0.02184, -0.14259],
        [4.40000, 0.99260, -0.35098, 1.24251, -0.15513, -0.02235, -0.14590],
        [4.50000, 0.98953, -0.36671, 1.22759, -0.15865, -0.02285, -0.14922],
        [4.60000, 0.98616, -0.38274, 1.21234, -0.16218, -0.02336, -0.15254],
        [4.70000, 0.98245, -0.39907, 1.19675, -0.16570, -0.02387, -0.15585],
        [4.80000, 0.97840, -0.41568, 1.18083, -0.16923, -0.02438, -0.15917],
        [4.90000, 0.97400, -0.43257, 1.16459, -0.17275, -0.02489, -0.16248],
        [5.00000, 0.96923, -0.44973, 1.14801, -0.17628, -0.02539, -0.16580],
        [5.10000, 0.96406, -0.46714, 1.13109, -0.17981, -0.02590, -0.16912],
        [5.20000, 0.95850, -0.48481, 1.11385, -0.18333, -0.02641, -0.17243],
        [5.30000, 0.95251, -0.50271, 1.09628, -0.18686, -0.02692, -0.17575],
        [5.40000, 0.94609, -0.52084, 1.07837, -0.19038, -0.02743, -0.17906],
        [5.50000, 0.93922, -0.53919, 1.06013, -0.19391, -0.02793, -0.18238],
        [5.60000, 0.93187, -0.55774, 1.04156, -0.19743, -0.02844, -0.18570],
        [5.70000, 0.92405, -0.57647, 1.02266, -0.20096, -0.02895, -0.18901],
        [5.80000, 0.91573, -0.59538, 1.00343, -0.20448, -0.02946, -0.19233],
        [5.90000, 0.90689, -0.61445, 0.98386, -0.20801, -0.02997, -0.19564],
        [6.00000, 0.89752, -0.63365, 0.96397, -0.21154, -0.03047, -0.19896],
        [6.10000, 0.88760, -0.65299, 0.94374, -0.21506, -0.03098, -0.20228],
        [6.20000, 0.87713, -0.67243, 0.92318, -0.21859, -0.03149, -0.20559],
        [6.30000, 0.86608, -0.69196, 0.90229, -0.22211, -0.03200, -0.20891],
        [6.40000, 0.85443, -0.71156, 0.88107, -0.22564, -0.03250, -0.21222],
        [6.50000, 0.84218, -0.73121, 0.85951, -0.22916, -0.03301, -0.21554],
        [6.60000, 0.82932, -0.75088, 0.83763, -0.23269, -0.03352, -0.21886],
        [6.70000, 0.81582, -0.77056, 0.81541, -0.23621, -0.03403, -0.22217],
        [6.80000, 0.80168, -0.79022, 0.79286, -0.23974, -0.03454, -0.22549],
        [6.90000, 0.78687, -0.80984, 0.76998, -0.24327, -0.03504, -0.22880],
        [7.00000, 0.77140, -0.82940, 0.74677, -0.24679, -0.03555, -0.23212],
        [7.10000, 0.75525, -0.84886, 0.72323, -0.25032, -0.03606, -0.23544],
        [7.20000, 0.73841, -0.86820, 0.69935, -0.25384, -0.03657, -0.23875],
        [7.30000, 0.72087, -0.88739, 0.67514, -0.25737, -0.03708, -0.24207],
        [7.40000, 0.70262, -0.90641, 0.65061, -0.26089, -0.03758, -0.24538],
        [7.50000, 0.68365, -0.92522, 0.62574, -0.26442, -0.03809, -0.24870],
        [7.60000, 0.66396, -0.94379, 0.60053, -0.26795, -0.03860, -0.25202],
        [7.70000, 0.64354, -0.96210, 0.57500, -0.27147, -0.03911, -0.25533],
        [7.80000, 0.62238, -0.98011, 0.54914, -0.27500, -0.03962, -0.25865],
        [7.90000, 0.60048, -0.99778, 0.52294, -0.27852, -0.04012, -0.26196],
        [8.00000, 0.57785, -1.01509, 0.49641, -0.28205, -0.04063, -0.26528],
        [8.10000, 0.55447, -1.03199, 0.46955, -0.28557, -0.04114, -0.26860],
        [8.20000, 0.53034, -1.04846, 0.44236, -0.28910, -0.04165, -0.27191],
        [8.30000, 0.50548, -1.06446, 0.41484, -0.29262, -0.04215, -0.27523],
        [8.40000, 0.47988, -1.07994, 0.38698, -0.29615, -0.04266, -0.27854],
        [8.50000, 0.45355, -1.09488, 0.35880, -0.29968, -0.04317, -0.28186],
        [8.60000, 0.42648, -1.10923, 0.33028, -0.30320, -0.04368, -0.28518],
        [8.70000, 0.39870, -1.12296, 0.30143, -0.30673, -0.04419, -0.28849],
        [8.80000, 0.37021, -1.13602, 0.27225, -0.31025, -0.04469, -0.29181],
        [8.90000, 0.34102, -1.14838, 0.24274, -0.31378, -0.04520, -0.29512],
        [9.00000, 0.31114, -1.16000, 0.21289, -0.31730, -0.04571, -0.29844],
        [9.10000, 0.28059, -1.17084, 0.18272, -0.32083, -0.04622, -0.30176],
        [9.20000, 0.24939, -1.18085, 0.15221, -0.32435, -0.04673, -0.30507],
        [9.30000, 0.21756, -1.19000, 0.12137, -0.32788, -0.04723, -0.30839],
        [9.40000, 0.18511, -1.19825, 0.09020, -0.33141, -0.04774, -0.31170],
        [9.50000, 0.15207, -1.20555, 0.05870, -0.33493, -0.04825, -0.31502],
        [9.60000, 0.11846, -1.21187, 0.02687, -0.33846, -0.04876, -0.31834],
        [9.70000, 0.08432, -1.21717, -0.00530, -0.34198, -0.04926, -0.32165],
        [9.80000, 0.04967, -1.22140, -0.03780, -0.34551, -0.04977, -0.32497],
        [9.90000, 0.01455, -1.22453, -0.07062, -0.34903, -0.05028, -0.32828],
        [10.00000, -0.02101 - 1.22652, -0.10378, -0.35256, -0.05079, -0.33160],
    ]

    x0 = GT_traj[0]
    # paramVel, paramFric;
    # steering velocity_desired duration
    ut = torch.Tensor([0.0, 0.0])
    steering = 0.34388248
    velocity = -0.46259581
    # ut = torch.Tensor([0.34388248, -0.46259581])
    # .077,0.2,1.012,0.9,1.05
    poly = torch.Tensor([-0.4397, 3.773e-5, 0.8677, 5.8e-6])
    velK = 0.077
    dt = 0.01
    mushr = MushrPlant()

    N = int(10 / dt)  # 10 secs
    x1 = torch.Tensor(GT_traj[0][1:4])
    x1 = mushr.SE2(x1[0], x1[1], x1[2])
    xd1 = torch.Tensor(GT_traj[0][4:7])

    print(f"x1 {x1} xd1 {xd1} ")
    ofs = open("/Users/Gary/pracsys/catkin_ws/py_traj.txt", "w")
    print(N)
    up = torch.Tensor([0.0, 0.0])
    for i in range(N):
        # print("---------------------");
        x0 = x1
        xd0 = xd1
        # x0 = row[1:4]
        # xd0 = row[4:]
        up[mushr.steering_idx] = mushr.poly_eval(poly, steering)
        up[mushr.velocity_idx] = velocity * velK
        # print(f"up: {up}")
        xd1 = mushr.xdot(xd0, up, dt)
        # print(f"xd1 {xd1}")
        x1 = mushr.integrate_SE2(x0, xd1, dt)
        # print(f"x1 {x1}")

        to_file(ofs, x1, xd1)
    ofs.close()


if __name__ == "__main__":
    test()
